{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T22:47:00.601941600Z",
     "start_time": "2024-01-15T22:46:53.656311200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from transformers import pipeline\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline, BitsAndBytesConfig , CodeGenTokenizer \n",
    "# from langchain.llms import HuggingFacePipeline \n",
    "# from langchain import PromptTemplate, LLMChain\n",
    "from transformers import AutoTokenizer , AutoModelForCausalLM\n",
    "import torch \n",
    "# torch.set_default_device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# model_id = 'microsoft/phi-2'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T22:47:00.609483900Z",
     "start_time": "2024-01-15T22:47:00.601941600Z"
    }
   },
   "id": "6303e039cfa41d3a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading shards'), FloatProgress(value=0.0, max=3.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dafd0c1124984ad18ffab576eb946ae6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='model-00003-of-00003.safetensors'), FloatProgress(value=0.0, max=4540516344.0), HTM…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a74706eaf3134b80922779cdf16ebc13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Loading checkpoint shards'), FloatProgress(value=0.0, max=3.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c5610b497914dfaa3d4b199ee67bed3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='generation_config.json'), FloatProgress(value=0.0, max=111.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a807cfe516194c5cbec005edbe17b66b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='tokenizer_config.json'), FloatProgress(value=0.0, max=1460.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e11690796fcc40c3ad6e1f16c0200c08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='tokenizer.model'), FloatProgress(value=0.0, max=493443.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a21ed4e780004780a9d877eef47cb1d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='tokenizer.json'), FloatProgress(value=0.0, max=1795303.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c7d81fdaacc4986ab309aa114df99a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='special_tokens_map.json'), FloatProgress(value=0.0, max=72.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a4b961e37564f63971c8f34ec362dae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, trust_remote_code=True, device_map='cuda', load_in_4bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, device_map='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T22:56:08.889352600Z",
     "start_time": "2024-01-15T22:47:00.605480600Z"
    }
   },
   "id": "dc8e2ae378e7be35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from transformers.generation import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StopWordCriteria(StoppingCriteria):\n",
    "    def __init__(self, stop_word):\n",
    "        self.stop_word = stop_word\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        text = tokenizer.decode(input_ids[0])\n",
    "        return self.stop_word in text\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T22:56:13.127006600Z",
     "start_time": "2024-01-15T22:56:13.121490600Z"
    }
   },
   "id": "aebbf6171803ce82",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T23:07:12.159521600Z",
     "start_time": "2024-01-15T23:07:12.145005100Z"
    }
   },
   "id": "5cd9b5808f077147",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> [INST] Translate the following question into German. Do not answer the question and do not say anything other than the translation.\n",
      "```\n",
      "What is the year that Julius Nepos becomes western Roman Emperor, deposing Glycerius?\n",
      "``` [/INST] \"Jahreszahl, in der Julius Nepos zum weströmischen Kaiser wird und Glycerius absetzt?\"</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = '''INST: Translate the following 5 questions into German without answering them. After translating, say nothing else.\n",
    "1. EN: What is the number of words in War and Peace by Leo Tolstoy?\n",
    "   DE: Wie viele Wörter hat Krieg und Frieden von Leo Tolstoi?\n",
    "2. EN: What is the number of episodes for the different regions in the PokÃ©mon anime?\n",
    "   DE: Wie viele Episoden gibt es für die verschiedenen Regionen im PokÃ©mon-Anime?\n",
    "3. EN: What is the number of hot dogs eaten by World record holder Joey Chestnut in 15 minutes?\n",
    "   DE: Wie viele Hot Dogs hat der Weltrekordhalter Joey Chestnut in 15 Minuten gegessen?\n",
    "4. EN: What is the number of people who have walked on the Moon?\n",
    "   DE: Wie viele Menschen sind auf dem Mond gelaufen?\n",
    "5. EN: What is the year that Julius Nepos becomes western Roman Emperor, deposing Glycerius?\n",
    "   DE:'''\n",
    "\n",
    "text = '''Translate the following question into German. Do not answer the question and do not say anything other than the translation.\n",
    "```\n",
    "What is the year that Julius Nepos becomes western Roman Emperor, deposing Glycerius?\n",
    "```'''\n",
    "\n",
    "\n",
    "messages = [\n",
    "    # {\n",
    "    #     \"role\": \"system\",\n",
    "    #     \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    # },\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\")\n",
    "inputs.to('cuda')\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=False, device='cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "# Despite returning the usual output, the streamer will also print the generated text to stdout.\n",
    "    _ = model.generate(**inputs, streamer=streamer, max_new_tokens=50, stopping_criteria=[StopWordCriteria('<|question_end|>')], do_sample=True, temperature=0.9, top_p=0.9, top_k=0, repetition_penalty=1.1, )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T23:10:32.115569800Z",
     "start_time": "2024-01-15T23:10:25.125720900Z"
    }
   },
   "id": "a123015b3236415c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc7c8c734df3c787"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T01:05:16.200934800Z",
     "start_time": "2023-10-07T01:05:16.197928700Z"
    }
   },
   "id": "68fc64cf133f0c96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T01:05:16.207453200Z",
     "start_time": "2023-10-07T01:05:16.200934800Z"
    }
   },
   "id": "3779041f5c0c830c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c20df3d6f2d5e8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "76e2c5cb18211e9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
